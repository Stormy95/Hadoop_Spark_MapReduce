# Hadoop_Spark_MapReduce

## MapReduce

Use of MRjob library to make map reduce requests (wordcount of dracula and analysis of purchases datasets) on Hadoop. 

## Spark

Use of pyspark to make spark requests (wordcount, analysis of a movie and rating datasets and arbresdeparis set) on Hadoop
